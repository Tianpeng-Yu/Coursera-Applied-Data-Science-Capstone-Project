{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggestions on Car Accident Severity In Seattle with Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Understanding: car accidents have great impact on people's lives. To help reduce the severity and frequency of car collision, I want to use the Seattle car collision data to generate insights on how modeling can help reduce accidents. Given the attributes including location, weather conditions and address type, we can see which factors attributes to car accidents most and how we can alert the driver in advance. \n",
    "\n",
    "This research and report would be beneficial to the local government, people who live in seattle and also car insurance. And later I would use machine learning models to interpret the logics and advice to reduce car accidents and injuries in Seattle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "#!pip install wget\n",
    "import wget\n",
    "url = 'https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Data-Collisions.csv'\n",
    "filename = wget.download(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the existing attributes and see if there is any valuable features\n",
    "num_count = ('SEVERITYCODE', 'OBJECTID', 'INCKEY', 'COLDETKEY', 'REPORTNO',\n",
    "       'STATUS', 'ADDRTYPE', 'INTKEY', 'LOCATION', 'EXCEPTRSNCODE','COLLISIONTYPE',\n",
    "       'PERSONCOUNT', 'PEDCOUNT', 'PEDCYLCOUNT', 'VEHCOUNT', 'INCDATE',\n",
    "       'INCDTTM', 'JUNCTIONTYPE', 'SDOT_COLCODE', 'SDOT_COLDESC',\n",
    "       'INATTENTIONIND', 'UNDERINFL', 'WEATHER', 'ROADCOND', 'LIGHTCOND',\n",
    "       'PEDROWNOTGRNT', 'SDOTCOLNUM', 'SPEEDING', 'ST_COLCODE', 'ST_COLDESC',\n",
    "       'SEGLANEKEY', 'CROSSWALKKEY', 'HITPARKEDCAR')\n",
    "\n",
    "for i in num_count:\n",
    "    print ('the number of each',':', i, 'is')\n",
    "    print (df[i].value_counts(dropna = False),'\\n')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result, I selected ADDRTYPE, COLLISIONTYPE, WEATHER, ROADCOND, LIGHTCOND as the features to analyze in my model. For INATTENTIONIND and UNDERINFL which means whether the driver was paying attention or using alcohol and for PEDROWNOTGRNT and SPEEDING, they only have positive and NA values. So I will need further data to include these features into the model in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization and pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First I will use all data incuding the NaN values to fit the models and then compare with the models excluding the NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the target variables and features that will be used\n",
    "df2 = df[['SEVERITYCODE', 'X', 'Y', 'ADDRTYPE', 'COLLISIONTYPE',\n",
    "          'WEATHER', 'ROADCOND', 'LIGHTCOND','LOCATION']]\n",
    "df2.rename(columns={'X':'Lon'}, inplace=True)\n",
    "df2.rename(columns={'Y':'Lat'}, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the data types\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the labeled data: Severity code\n",
    "df['SEVERITYCODE'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of empty inputs in \" ROADCOND\"\n",
    "df['ROADCOND'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of empty inputs in \"WEATHER\"\n",
    "df['WEATHER'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice: installing seaborn might takes a few minutes\n",
    "#!conda install -c anaconda seaborn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "pic1 = sns.countplot(x=\"ADDRTYPE\", hue = 'SEVERITYCODE', data=df2, palette=\"rocket\")\n",
    "plt.title('The Number of Accidents by Collision Address Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic2 = sns.countplot(x=\"WEATHER\", hue = 'SEVERITYCODE', data=df2, palette=\"rocket\")\n",
    "plt.title('The Number of Accidents by Collision Address Type')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Folium to see on the map\n",
    "!conda install -c conda-forge folium=0.5.0 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "print('Folium installed and imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_acc = df2.groupby(['Lon', 'Lat', 'LOCATION']).size().reset_index(name='Count') \n",
    "df2_acc['Frequency'] = df2_acc['Count'].apply(lambda x: 'Often' if x>15  else ('Sometimes' if x > 5 else 'Few'))\n",
    "df2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traffic_map = folium.Map(location=[47.608, -122.335],zoom_start = 10)\n",
    "colordict = {'Few': 'blue', 'Sometimes': 'orange', 'Often': 'red'}\n",
    "\n",
    "\n",
    "for Lon, Lat, LOCATION, Count, Frequency in zip(df2_acc['Lon'], df2_acc['Lat'], df2_acc['LOCATION'], df2_acc['Count'], df2_acc['Frequency']):\n",
    "    folium.CircleMarker(\n",
    "        [Lat, Lon],\n",
    "        radius=.1*Count,\n",
    "        popup = ('Street: ' + str(LOCATION).capitalize() + '<br>'\n",
    "                 'Accident: ' + str(Count) + '<br>'\n",
    "                 'Accident level: ' + str(Frequency) +'%'\n",
    "                ),\n",
    "        color='b',\n",
    "        key_on = Frequency,\n",
    "        threshold_scale=[0,1,2,3],\n",
    "        fill_color=colordict[Frequency],\n",
    "        fill=True,\n",
    "        fill_opacity=0.7\n",
    "        ).add_to(traffic_map)\n",
    "\n",
    "\n",
    "\n",
    "traffic_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing: Feature selection/extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.groupby(['WEATHER'])['SEVERITYCODE'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Categorical features to numerical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_ADDRTYPE = {'ADDRTYPE': {'Block':2, 'Intersection':3, 'Alley':4, np.nan: 0} }\n",
    "df2.replace(encoding_ADDRTYPE, inplace=True)\n",
    "df2['ADDRTYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_COLLISIONTYPE = {'COLLISIONTYPE': \n",
    "                          {'Parked Car':2, \n",
    "                           'Angles':3, \n",
    "                           'Rear Ended':4, \n",
    "                           'Other':1,\n",
    "                           'Sideswipe':5,\n",
    "                           'Left Turn':6, \n",
    "                           'Pedestrian':7, \n",
    "                           'Cycles':8, \n",
    "                            np.NaN :0, \n",
    "                           'Right Turn':9, \n",
    "                           'Head On':10} }\n",
    "df2.replace(encoding_COLLISIONTYPE, inplace=True)\n",
    "df2['COLLISIONTYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_WEATHER = {'WEATHER': \n",
    "                    {np.nan:0,\n",
    "                     'Unknown':1,\n",
    "                     'Other':1,\n",
    "                     'Clear':2, \n",
    "                     'Raining':3, \n",
    "                     'Overcast':4, \n",
    "                     'Snowing':5, \n",
    "                     'Fog/Smog/Smoke':6, \n",
    "                     'Sleet/Hail/Freezing Rain':7, \n",
    "                     'Blowing Sand/Dirt':8, \n",
    "                     'Severe Crosswind':9,\n",
    "                     'Partly Cloudy':10}}\n",
    "\n",
    "df2.replace(encoding_WEATHER, inplace=True)\n",
    "df2['WEATHER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_ROADCOND = {'ROADCOND': \n",
    "                     {np.nan:0,\n",
    "                      'Unknown':1,\n",
    "                      'Other':1,\n",
    "                      'Dry':2, \n",
    "                      'Wet':3, \n",
    "                      'Ice':4,  \n",
    "                      'Snow/Slush':5, \n",
    "                      'Standing Water' :6, \n",
    "                      'Sand/Mud/Dirt':7,\n",
    "                      'Oil':8} }\n",
    "\n",
    "df2.replace(encoding_ROADCOND, inplace=True)\n",
    "df2['ROADCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_LIGHTCOND = {'LIGHTCOND': \n",
    "                     {np.nan:0,\n",
    "                      'Unknown':1,\n",
    "                      'Other':1,\n",
    "                      'Daylight':2, \n",
    "                      'Dark - Street Lights On':3, \n",
    "                      'Dusk':4,  \n",
    "                      'Dawn':5, \n",
    "                      'Dark - No Street Lights' :6, \n",
    "                      'Dark - Street Lights Off':7,\n",
    "                      'Dark - Unknown Lighting':1} }\n",
    "\n",
    "df2.replace(encoding_LIGHTCOND, inplace=True)\n",
    "df2['LIGHTCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = df2[['ADDRTYPE', 'COLLISIONTYPE', 'WEATHER', 'ROADCOND', 'LIGHTCOND']]\n",
    "Feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Feature\n",
    "Y = df2['SEVERITYCODE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "\n",
    "Ks = 12\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "ConfustionMx = [];\n",
    "for n in range(3,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    knn = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat=knn.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot to find the best k\n",
    "plt.plot(range(1,Ks),mean_acc)\n",
    "plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3xstd'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) \n",
    "\n",
    "knn_best = KNeighborsClassifier(n_neighbors=mean_acc.argmax()+1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with data (occurs in-place)\n",
    "knn_best.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_best.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(C=0.01, solver=\"liblinear\").fit(X_train,y_train)\n",
    "LR\n",
    "\n",
    "yhat_lr = LR.predict(X_test)\n",
    "yhat_lr\n",
    "\n",
    "print(confusion_matrix(y_test, yhat_lr))  \n",
    "print(classification_report(y_test, yhat_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data is underfit, so I created another dataframe without NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create another dataframe without NA values to compare later\n",
    "df2_dropna = df2.dropna()\n",
    "df2_dropna\n",
    "df2_dropna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance the data\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df2_dropna_major = df2_dropna[df2_dropna.SEVERITYCODE == 1]\n",
    "df2_dropna_minor = df2_dropna[df2_dropna.SEVERITYCODE == 2]\n",
    "\n",
    "df2_dropna_major_desample = resample(df2_dropna_major, replace = False, n_samples = 56000, random_state = 123)\n",
    "balanced_df2 = pd.concat([df2_dropna_major_desample,df2_dropna_minor])\n",
    "balanced_df2['SEVERITYCODE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for DF_DROPNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "pic_dropna1 = sns.countplot(x=\"ADDRTYPE\", hue = 'SEVERITYCODE', data=balanced_df2, palette=\"rocket\")\n",
    "plt.title('The Number of Accidents by Collision Address Type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_dropna2 = sns.countplot(x=\"WEATHER\", hue = 'SEVERITYCODE', data=balanced_df2, palette=\"rocket\")\n",
    "plt.title('The Number of Accidents by Collision Address Type')\n",
    "plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_dropna3 = sns.countplot(x=\"ROADCOND\", hue = 'SEVERITYCODE', data=balanced_df2, palette=\"rocket\")\n",
    "plt.title('The Number of Accidents by Road Condition')\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge folium=0.5.0 --yes\n",
    "import folium\n",
    "print('Folium installed and imported!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_acc = balanced_df2.groupby(['Lon', 'Lat', 'LOCATION']).size().reset_index(name='Count') \n",
    "df2_acc['Frequency'] = df2_acc['Count'].apply(lambda x: 'Often' if x>15  else ('Sometimes' if x > 5 else 'Few'))\n",
    "df2_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_map = folium.Map(location=[47.608, -122.335],zoom_start = 10)\n",
    "colordict = {'Few': 'blue', 'Sometimes': 'orange', 'Often': 'red'}\n",
    "\n",
    "\n",
    "for Lon, Lat, LOCATION, Count, Frequency in zip(df2_acc['Lon'], df2_acc['Lat'], df2_acc['LOCATION'], df2_acc['Count'], df2_acc['Frequency']):\n",
    "    folium.CircleMarker(\n",
    "        [Lat, Lon],\n",
    "        radius=.1*Count,\n",
    "        popup = ('Street: ' + str(LOCATION).capitalize() + '<br>'\n",
    "                 'Accident: ' + str(Count) + '<br>'\n",
    "                 'Accident level: ' + str(Frequency) +'%'\n",
    "                ),\n",
    "        color='b',\n",
    "        key_on = Frequency,\n",
    "        threshold_scale=[0,1,2,3],\n",
    "        fill_color=colordict[Frequency],\n",
    "        fill=True,\n",
    "        fill_opacity=0.7\n",
    "        ).add_to(traffic_map)\n",
    "\n",
    "\n",
    "\n",
    "traffic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoding_ADDRTYPE = {'ADDRTYPE': {'Block':2, 'Intersection':3} }\n",
    "df2_dropna.replace(encoding_ADDRTYPE, inplace=True)\n",
    "df2_dropna['ADDRTYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_COLLISIONTYPE = {'COLLISIONTYPE': \n",
    "                          {'Parked Car':2, \n",
    "                           'Angles':3, \n",
    "                           'Rear Ended':4, \n",
    "                           'Other':1,\n",
    "                           'Sideswipe':5,\n",
    "                           'Left Turn':6, \n",
    "                           'Pedestrian':7, \n",
    "                           'Cycles':8, \n",
    "                           'Right Turn':9, \n",
    "                           'Head On':10} }\n",
    "df2_dropna.replace(encoding_COLLISIONTYPE, inplace=True)\n",
    "df2_dropna['COLLISIONTYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_WEATHER = {'WEATHER': \n",
    "                    {'Unknown':1,\n",
    "                     'Other':1,\n",
    "                     'Clear':2, \n",
    "                     'Raining':3, \n",
    "                     'Overcast':4, \n",
    "                     'Snowing':5, \n",
    "                     'Fog/Smog/Smoke':6, \n",
    "                     'Sleet/Hail/Freezing Rain':7, \n",
    "                     'Blowing Sand/Dirt':8, \n",
    "                     'Severe Crosswind':9,\n",
    "                     'Partly Cloudy':10}}\n",
    "\n",
    "df2_dropna.replace(encoding_WEATHER, inplace=True)\n",
    "df2_dropna['WEATHER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_ROADCOND = {'ROADCOND': \n",
    "                     {'Unknown':1,\n",
    "                      'Other':1,\n",
    "                      'Dry':2, \n",
    "                      'Wet':3, \n",
    "                      'Ice':4,  \n",
    "                      'Snow/Slush':5, \n",
    "                      'Standing Water' :6, \n",
    "                      'Sand/Mud/Dirt':7,\n",
    "                      'Oil':8} }\n",
    "\n",
    "df2_dropna.replace(encoding_ROADCOND, inplace=True)\n",
    "df2_dropna['ROADCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_LIGHTCOND = {'LIGHTCOND': \n",
    "                     {'Unknown':1,\n",
    "                      'Other':1,\n",
    "                      'Daylight':2, \n",
    "                      'Dark - Street Lights On':3, \n",
    "                      'Dusk':4,  \n",
    "                      'Dawn':5, \n",
    "                      'Dark - No Street Lights' :6, \n",
    "                      'Dark - Street Lights Off':7,\n",
    "                      'Dark - Unknown Lighting':1} }\n",
    "\n",
    "df2_dropna.replace(encoding_LIGHTCOND, inplace=True)\n",
    "df2_dropna['LIGHTCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_dropna['SEVERITYCODE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance the data\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df2_dropna_major = df2_dropna[df2_dropna.SEVERITYCODE == 1]\n",
    "df2_dropna_minor = df2_dropna[df2_dropna.SEVERITYCODE == 2]\n",
    "\n",
    "df2_dropna_major_desample = resample(df2_dropna_major, replace = False, n_samples = 56000, random_state = 123)\n",
    "balanced_df2 = pd.concat([df2_dropna_major_desample,df2_dropna_minor])\n",
    "balanced_df2['SEVERITYCODE'].value_counts()\n",
    "\n",
    "Feature = balanced_df2[['ADDRTYPE', 'COLLISIONTYPE', 'WEATHER', 'ROADCOND', 'LIGHTCOND']]\n",
    "Feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Feature\n",
    "Y = balanced_df2['SEVERITYCODE'].values\n",
    "print (X.shape)\n",
    "print (Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "\n",
    "Ks = 12\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "ConfustionMx = [];\n",
    "for n in range(3,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    knn = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat=knn.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot to find the best k\n",
    "plt.plot(range(1,Ks),mean_acc)\n",
    "plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3xstd'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) \n",
    "\n",
    "knn_best = KNeighborsClassifier(n_neighbors=mean_acc.argmax()+1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with data (occurs in-place)\n",
    "knn_best.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_best.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import f1_score\n",
    "jc1 = jaccard_similarity_score(y_test, y_pred)\n",
    "fs1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(jc1,fs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "knn_best = KNeighborsClassifier(n_neighbors=mean_acc.argmax()+1).fit(X_train, y_train)\n",
    "print(\"Test set score: {:.4f}\".format(knn_best.score(X_test, y_test)))\n",
    "\n",
    "y_scores = knn_best.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1], pos_label= 2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pylab as pl\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "random_state = np.random.RandomState(0)\n",
    "# shuffle and split training and test sets\n",
    "X, Y = shuffle(X, Y, random_state=random_state)\n",
    "half = int(n_samples / 2)\n",
    "X_train, X_test = X[:half], X[half:]\n",
    "y_train, y_test = Y[:half], Y[half:]\n",
    "\n",
    "classifier = svm.SVC(kernel='linear', probability=True)\n",
    "SVC_probas = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "# Compute ROC curve and area the curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, SVC_probas[:, 1],pos_label=2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (\"Area under the ROC curve : %f\" % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.clf()\n",
    "pl.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "pl.plot([0, 1], [0, 1], 'k--')\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.ylim([0.0, 1.0])\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('ROC Curve of SVM')\n",
    "pl.legend(loc=\"lower right\")\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predsvm = classifier.predict(X_train)\n",
    "print(confusion_matrix(y_test, y_predsvm))  \n",
    "print(classification_report(y_test, y_predsvm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_predlr = LR.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_predlr))  \n",
    "print(classification_report(y_test, y_predlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "y_predlr_probas = LR.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute ROC curve and area the curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_predlr_probas, pos_label=2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print (\"Area under the ROC curve : %f\" % roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve of Logistic Regression')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_dropna.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "194673-184146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
